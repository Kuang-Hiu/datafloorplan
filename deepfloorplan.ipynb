{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DoMeFNOVPl-"
   },
   "source": [
    "### Installation\n",
    "1. Run the first 2 cells\n",
    "2. Restart runtime\n",
    "3. Run the rest of the jupyter notebooks (do not run the first 2 cells again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZNGXP8N_VPmE",
    "outputId": "470a5f33-aa28-45a7-a8cf-f8ae8e5bf421"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "from roboflow import Roboflow\n",
    "from PIL import Image\n",
    "import urllib3\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('mb2_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1762e86cfa0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(pix[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pix = np.array(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class point():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "def get_degree_three_points(p, p1, p2):\n",
    "    v1 = np.array([p1.x - p.x, p1.y - p.y])\n",
    "    v2 = np.array([p2.x - p.x, p2.y - p.y])\n",
    "    unit_v1 = v1 / np.linalg.norm(v1)\n",
    "    unit_v2 = v2 / np.linalg.norm(v2)\n",
    "    dot_product = np.dot(unit_v1, unit_v2)\n",
    "    angle = np.math.atan2(np.linalg.det([unit_v1, unit_v2]), dot_product)\n",
    "    degree = np.round(np.degrees(angle), 2)\n",
    "    if degree > 90:\n",
    "        degree = 180 - degree\n",
    "    return abs(degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def distance(p1, p2):\n",
    "    return math.sqrt((p1.x-p2.x)**2 + (p1.y-p2.y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_boundary(point_boundary):\n",
    "    for i in range(len(point_boundary)-1):\n",
    "        p0 = point(point_boundary[i][0],point_boundary[i][1])\n",
    "        p1 = point(point_boundary[i + 1][0],point_boundary[i + 1][1])\n",
    "        p = point(point_boundary[i][0],point_boundary[i][0] + 100)\n",
    "        angle = get_degree_three_points(p0, p1, p)\n",
    "        if (angle < 30 and angle != 0 and angle != 90) or math.abs(p0.x - p1.x) < 15:\n",
    "            if point_boundary[i + 1][0] > point_boundary[i][0]:\n",
    "                point_boundary[i + 1][0] = point_boundary[i][0]\n",
    "            else:\n",
    "                point_boundary[i ][0] = point_boundary[i + 1][0]\n",
    "        if (angle > 60 and angle != 90 and angle != 0) or math.abs(p0.y - p1.y) < 15 :\n",
    "            if point_boundary[i + 1][1] > point_boundary[i][1]:\n",
    "                point_boundary[i + 1][1] = point_boundary[i][1]\n",
    "            else:\n",
    "                point_boundary[i ][1] = point_boundary[i + 1][1]\n",
    "    return point_boundary\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKFlssqbVPmF"
   },
   "source": [
    "### Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4VRom9mqBPT",
    "outputId": "12900c33-7f46-48a1-b4b3-09028e45745c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'dfp.utils._paths' from 'D:\\\\House3D\\\\Input_processing\\\\TF2DeepFloorplan\\\\dfp\\\\utils\\\\_paths.py'>\n",
      "<module 'dfp._paths' from 'D:\\\\House3D\\\\Input_processing\\\\TF2DeepFloorplan\\\\dfp\\\\_paths.py'>\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10632\\4105168599.py:19: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "root = 'D:\\\\House3D\\\\Input_processing'\n",
    "sys.path.append(root + '\\\\TF2DeepFloorplan')\n",
    "sys.path.append(root + '\\\\TF2DeepFloorplan\\\\dfp')\n",
    "from dfp.net import *\n",
    "from dfp.data import *\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import Namespace\n",
    "import os\n",
    "import gc\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "sys.path.append(root + '\\\\TF2DeepFloorplan\\\\dfp\\\\utils')\n",
    "from dfp.utils.rgb_ind_convertor import *\n",
    "from dfp.utils.util import *\n",
    "from dfp.utils.legend import *\n",
    "from dfp.deploy import *\n",
    "print(tf.test.is_gpu_available())\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def door_detection(img_path = './30939153.jpg'):\n",
    "    doors = []\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        #detection\n",
    "        rf = Roboflow(api_key=\"7W0fIqzuiJGplpXG0C5L\")\n",
    "\n",
    "        workspace = rf.workspace(\"kuanghiu\")\n",
    "\n",
    "        project = workspace.project(\"door-yvyzd\")\n",
    "\n",
    "        version = project.version(1)\n",
    "\n",
    "        model = version.model\n",
    "\n",
    "        prediction = model.predict(img_path)\n",
    "\n",
    "        json_file = prediction.json()\n",
    "        #save results\n",
    "        for it in json_file['predictions']:\n",
    "            door = np.zeros((img.shape[0],img.shape[1]))\n",
    "            door[int(it['y'] - it['height']/2) : int(it['y']+it['height']/2), int(it['x']- it['width']/2) : int(it['x'] + it['width']/2)] = 255\n",
    "            doors.append(door)\n",
    "        print('Detect door sussecful. Have {} doors in plan'.format(len(doors)))\n",
    "    except:\n",
    "        print('Something wrong. We dont find any door in plan')\n",
    "    return doors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "30DTDbxbwm3O"
   },
   "outputs": [],
   "source": [
    "def resize_to_square(im, color = [0]):\n",
    "    \n",
    "    img_size = max(im.shape)\n",
    "    old_size = im.shape\n",
    "    ratio = float(img_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])    \n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    delta_w = img_size - new_size[1]\n",
    "    delta_h = img_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    #color = [0]\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv.BORDER_CONSTANT,value=color)\n",
    "    return new_im #cv.resize(new_im,(256,256), interpolation = cv.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import *\n",
    "\n",
    "def mask2labelme(mask):\n",
    "\n",
    "    annotation = Annotation.from_mask(mask//255, image = None)\n",
    "    \n",
    "    polygons, hierarchy = annotation.polygons\n",
    "    #polygon = Polygons.from_mask(mask)\n",
    "    list_polygon = [ps.reshape(-1, 2) for ps in polygons]\n",
    "    thres = 3\n",
    "    '''for p in list_polygon:\n",
    "        if thres < len(p):\n",
    "            thres = len(p)'''\n",
    "    lis_poly = []\n",
    "    for p in list_polygon:\n",
    "        point = []\n",
    "        if len(p) >=  thres:\n",
    "            lis_points = p.reshape(-1, 2)\n",
    "            point.append([int(lis_points[0][0]), int(lis_points[0][1])])\n",
    "            for i in range(len(lis_points)):\n",
    "                if (abs(lis_points[i][0] - point[-1][0]) >1) or (abs(lis_points[i][1] - point[-1][1]) >1):\n",
    "                    point.append([int(lis_points[i][0]), int(lis_points[i][1])])\n",
    "        lis_poly.append(point)\n",
    "    return lis_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzqbdPC0uJNc",
    "outputId": "236ce87e-20bd-42e1-bf0c-915b33c1b5d4"
   },
   "outputs": [],
   "source": [
    "def deepfloorplan(img_path):\n",
    "    args = Namespace(image = img_path ,\n",
    "            weight=root + '\\\\log\\\\store\\\\G',loadmethod='log',\n",
    "            postprocess=True,colorize=True,\n",
    "            save=None)\n",
    "    result = main(args)\n",
    "    img = result.astype(np.uint8)\n",
    "    img = resize_to_square(img,color = [0])\n",
    "    numpydata = np.asarray(img)\n",
    "    return numpydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocces_data(img_path):\n",
    "    \n",
    "    numpydata = deepfloorplan(img_path)\n",
    "    doors = door_detection(img_path)\n",
    "    #Detection raw inside map\n",
    "    inside_down = np.array([10,100,10])\n",
    "    inside_up = np.array([255,255,255])\n",
    "    mask_inside = cv2.inRange(numpydata, inside_down, inside_up)\n",
    "     #Detection raw opening map\n",
    "    opening_down = np.array([255-10, 60-10,128-10])\n",
    "    opening_up = np.array([255, 60+10,128+10])\n",
    "    mask_opening = cv2.inRange(numpydata, opening_down, opening_up)\n",
    "    \n",
    "    #Refine inside map \n",
    "    h_size = mask_inside.shape[1]\n",
    "    w_size = mask_inside.shape[0]\n",
    "    for r in range(0,h_size):\n",
    "        if max(mask_inside[r]) >0:\n",
    "            start = min(np.argwhere(mask_inside[r] == 255))[0]\n",
    "            end  = max(np.argwhere(mask_inside[r] == 255))[0]\n",
    "            mask_inside[r][start:end] = 255\n",
    "\n",
    "    mask_inside_transpose = mask_inside.transpose()\n",
    "\n",
    "    for r in range(0,w_size):\n",
    "        if max(mask_inside_transpose[r]) >0:\n",
    "            start = min(np.argwhere(mask_inside_transpose[r] == 255))[0]\n",
    "            end  = max(np.argwhere(mask_inside_transpose[r] == 255))[0]\n",
    "            mask_inside_transpose[r][start:end] = 255\n",
    "    mask_inside = mask_inside_transpose.transpose() \n",
    "    \n",
    "    #save boundary to points list\n",
    "    _boundary = mask2labelme(mask_inside)\n",
    "    #print(point_boundary)\n",
    "    point_boundary = np.array(_boundary, np.int32)\n",
    "    '''for i in range(len(_boundary[0])-1):\n",
    "        p0 = point(_boundary[0][i][0],_boundary[0][i][1])\n",
    "        p1 = point(_boundary[0][i + 1][0],_boundary[0][i + 1][1])\n",
    "        d = distance(p0, p1)\n",
    "        if d < 5:\n",
    "            _boundary[0][i + 1][0] = _boundary[0][i][0]\n",
    "            _boundary[0][i + 1][1] = _boundary[0][i][1]\n",
    "    indexes = np.unique(_boundary[0], return_index=True, axis = 0)[1]\n",
    "    point_boundary = refine_boundary(np.array([_boundary[0][index] for index in sorted(indexes)]))'''\n",
    "\n",
    "    #Detection main door\n",
    "    door = resize_to_square(sum(doors),color = [0])\n",
    "    #save boundary to points list\n",
    "    point_door = mask2labelme(door)\n",
    "    point_door = np.array(point_door, np.int32)\n",
    "    \n",
    "    boundary = resize_to_square(cv.imread(img_path),color = [255, 255, 255])*0\n",
    "    main_door  = resize_to_square(cv.imread(img_path),color = [255, 255, 255])*0\n",
    "    \n",
    "    cv2.polylines(boundary, [point_boundary], True, (255,0,0), thickness=5)\n",
    "    cv2.polylines(main_door, point_door, True, (255,0,0), thickness=25)\n",
    "    for i in range(h_size):\n",
    "        for j in range(w_size):\n",
    "            if main_door[:,:,0][i, j] == 255 and boundary[:,:,0][i, j] != 0:\n",
    "                main_door[:,:,0][i, j] = 255\n",
    "            else:\n",
    "                main_door[:,:,0][i, j] = 0\n",
    "    \n",
    "    #save boundary to points list\n",
    "    point_maindoor = mask2labelme(main_door[:,:,0])\n",
    "    #point_maindoor = np.array(point_maindoor, np.int32)\n",
    "              \n",
    "    return point_boundary, point_maindoor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img_path):\n",
    "    \n",
    "    point_boundary, point_maindoor = preprocces_data(img_path)\n",
    "    ratio = 256 / max(cv.imread(img_path).shape[0], cv.imread(img_path).shape[1])\n",
    "\n",
    "    point_boundary = (point_boundary*ratio).astype('int32')\n",
    "    #point_maindoor = (point_maindoor*ratio)\n",
    "\n",
    "    wall  = cv.resize(cv.imread(img_path), (256, 256))*0\n",
    "    inside  = cv.resize(cv.imread(img_path), (256, 256))*0\n",
    "\n",
    "    cv2.polylines(wall, [point_boundary], True, (127,127,127), thickness=5) # boudary\n",
    "    cv2.fillPoly(inside,[point_boundary],(255,255,255)) #inside\n",
    "    i = 0\n",
    "    for p in point_maindoor:\n",
    "        i+=1\n",
    "        door  = cv.resize(cv.imread(img_path), (256, 256))*0\n",
    "        p = (np.array(p, np.int32)*ratio).astype('int32')\n",
    "        cv2.polylines(door, [p], True, (128,128,128), thickness=5)\n",
    "\n",
    "\n",
    "\n",
    "        #channel 0\n",
    "        c0 = wall[:,:,0] + door[:,:,0]\n",
    "        c0 = np.where(c0 != 128, c0, 0)\n",
    "        #channel 1, 2\n",
    "        c1 = np.zeros(c0.shape)\n",
    "        c2 = np.zeros(c0.shape)\n",
    "        #channel 3\n",
    "        c3 = inside[:,:,0]\n",
    "\n",
    "        img = np.stack([c0,c1,c2,c3], axis=-1).astype(np.uint8)\n",
    "        output = Image.fromarray(img)\n",
    "\n",
    "        output.save(img_path.split('.')[0] + f\"_{i}.png\")\n",
    "        print(f'solved file: {img_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 1048576 values, but the requested shape requires a multiple of 786432 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresize_img\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mresize_img\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresize_img\u001b[39m(img_path):\n\u001b[1;32m----> 3\u001b[0m     point_boundary, point_maindoor \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocces_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(cv\u001b[38;5;241m.\u001b[39mimread(img_path)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], cv\u001b[38;5;241m.\u001b[39mimread(img_path)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      6\u001b[0m     point_boundary \u001b[38;5;241m=\u001b[39m (point_boundary\u001b[38;5;241m*\u001b[39mratio)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mpreprocces_data\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocces_data\u001b[39m(img_path):\n\u001b[1;32m----> 3\u001b[0m     numpydata \u001b[38;5;241m=\u001b[39m \u001b[43mdeepfloorplan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     doors \u001b[38;5;241m=\u001b[39m door_detection(img_path)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#Detection raw inside map\u001b[39;00m\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mdeepfloorplan\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeepfloorplan\u001b[39m(img_path):\n\u001b[0;32m      2\u001b[0m     args \u001b[38;5;241m=\u001b[39m Namespace(image \u001b[38;5;241m=\u001b[39m img_path ,\n\u001b[0;32m      3\u001b[0m             weight\u001b[38;5;241m=\u001b[39mroot \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m'\u001b[39m,loadmethod\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m             postprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,colorize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m             save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     img \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m      8\u001b[0m     img \u001b[38;5;241m=\u001b[39m resize_to_square(img,color \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mD:\\House3D\\Input_processing\\TF2DeepFloorplan\\dfp\\deploy.py:135\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(config: argparse\u001b[38;5;241m.\u001b[39mNamespace) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m--> 135\u001b[0m     model, img, shp \u001b[38;5;241m=\u001b[39m \u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mloadmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    137\u001b[0m         logits_cw, logits_r \u001b[38;5;241m=\u001b[39m predict(model, img, shp)\n",
      "File \u001b[1;32mD:\\House3D\\Input_processing\\TF2DeepFloorplan\\dfp\\deploy.py:48\u001b[0m, in \u001b[0;36minit\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     45\u001b[0m img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(img, [\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m512\u001b[39m])\n\u001b[0;32m     46\u001b[0m img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(img, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 48\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mloadmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtflite\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, img, shp\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 1048576 values, but the requested shape requires a multiple of 786432 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "resize_img('1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "rgba_image = PIL.Image.open('./Capture.png')\n",
    "rgb_image = rgba_image.convert('RGB')\n",
    "rgb_image.save('output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgba_image.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in os.listdir('C:/Users/kuanghiu/Deepfloorplan/test/input/'):\n",
    "    try:\n",
    "        resize_img('C:/Users/kuanghiu/Deepfloorplan/test/input/' + img_path)\n",
    "    except:\n",
    "        print(f'error in file: {img_path}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_img('C:/Users/kuanghiu/Deepfloorplan/test/input/mb3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deepfloorplan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
